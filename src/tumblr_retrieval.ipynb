{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Skript for retreving tumblr posts with API.\n",
    "## Based on [tumblr-scraper](https://github.com/boilingpenguin/tumblr-scraper)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import pytumblr\n",
    "import unicodecsv as csv\n",
    "from unidecode import unidecode\n",
    "import calendar\n",
    "import time"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Tumblr credentials:\n",
    "tumblr = pytumblr.TumblrRestClient(\n",
    "  '<...>'\n",
    ")\n",
    "\n",
    "\"\"\"Search parameters:\n",
    "\n",
    "Tumblr's API only supports searching for a single tag at a time.\n",
    "Filter options are text, html, or raw.\n",
    "Before - only search for posts before this time - in seconds past the epoch.\n",
    "You can use calendar.timegm(time.gmtime()) to use the current epoch.\n",
    "\"\"\"\n",
    "\n",
    "before = calendar.timegm(time.gmtime())\n",
    "\n",
    "TAG: str = 'essst√∂rung'\n",
    "FILTER: str = 'raw'\n",
    "OUTPUT_PATH: str = '../data/'\n",
    "FILE_PATH = OUTPUT_PATH + 'TumblrSearch-' + str(before) + '-' + TAG + '.csv'\n",
    "\n",
    "with open(FILE_PATH, mode='ab') as results_file:\n",
    "\t\tresults_writer = csv.writer(results_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_ALL)\n",
    "\t\tresults_writer.writerow([\"timeStamp\", \"URL\", \"blogName\", \"title\", \"tags\", \"body\"])\n",
    "\n",
    "\n",
    "print(\"Searching Tumblr for 100 posts tagged \\'\" + TAG + \"\\'\")\n",
    "\n",
    "j = 1\n",
    "\n",
    "\"\"\"It is important to pay attention to the number of batches chosen here.\n",
    "After a certain rate, users will receive an API call limit.\n",
    "Using 20 batches brings around 450 posts.\n",
    "\"\"\"\n",
    "\n",
    "while j < 20:\n",
    "\t# Run the tag search and snag the results\n",
    "\tsearch_results = tumblr.tagged(TAG, filter=FILTER, before=before)\n",
    "\tprint(\"Batch \" + str(j) + \" of 20\")\n",
    "\tprint(str(len(search_results)) + \" results retreived\")\n",
    "\tfor i in search_results:\n",
    "\t\tblog_name = (i)['blog_name']\n",
    "\t\tdate = (i)['date']\n",
    "\n",
    "\t\turl = (i)['post_url']\n",
    "\n",
    "\t\ttry:\n",
    "\t\t\ttitle = (i)['title']\n",
    "\t\texcept:\n",
    "\t\t\ttitle = \"Couldn't Get Title\"\n",
    "\t\ttry:\n",
    "\t\t\ttags = (i)['tags']\n",
    "\t\texcept:\n",
    "\t\t\ttags = \"Couldn't Get tags\"\n",
    "\t\ttry:\n",
    "\t\t\tbody = (i)['body']\n",
    "\t\texcept:\n",
    "\t\t\tbody = \"Couldn't Get Post Body\"\n",
    "\t\twith open(FILE_PATH, mode='ab') as results_file:\n",
    "\t\t\tresults_writer = csv.writer(results_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_ALL)\n",
    "\t\t\ttry:\n",
    "\t\t\t\tresults_writer.writerow([date, unidecode(url), blog_name, title, tags, body])\n",
    "\t\t\t\tprint(\"Successfully Wrote Row for post from \" + date)\n",
    "\t\t\texcept:\n",
    "\t\t\t\tprint(\"Error Writing Row\")\n",
    "\t#Next we make note of the oldest timestamp\n",
    "\t\toldest_time = (i)['timestamp']\n",
    "\tbefore = oldest_time\n",
    "\tj = j + 1\n",
    "print(\"Finished!\")\n",
    "print(\"Saved CSV to \" + FILE_PATH)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
